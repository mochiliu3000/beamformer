{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机追踪（Random Persuit）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from multiprocessing import Pool\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "thread_num = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_pursuit(data_x, data_y, inx_h, l_inx, N, inx_p = -1, n_pred = 1, s_size = -1, percent_value = -1, method = 'inverse'):\n",
    "    \"\"\"random pursuit core function.\n",
    "    # Arguments\n",
    "        data_x : A ndarray, a series x value.\n",
    "        data_y : A ndarray, corresponding series of y value.\n",
    "        inx_h: Integer, max index of history data.\n",
    "        l_inx: Integer, length of history data used for pursuit. Or say, the size of sliding window.\n",
    "        N: Interger, number of points in each regression.\n",
    "        inx_p: Integer, the index of the data point to predict. If set to -1, the point with index (inx_h+1) will be predicted.\n",
    "        n_pred: Interger, number of points to predict with sliding window.\n",
    "        s_size: Interger, the moving step size of sliding window.\n",
    "        percent_value: Float, max percentage for weight recaculation.\n",
    "        method: String, 'inverse' or 'softmax', how weights are calculated from losses\n",
    "    # Returns\n",
    "        pred: Prediction value for the data point you sepecified.\n",
    "        forward_loss: Prediction forward L2 loss.\n",
    "        backward_loss: Prediction backward L2 loss.\n",
    "    # Raises\n",
    "        ValueError: Input error OR calculation error.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(data_x) == 0 or len(data_y) == 0 or len(data_x) < len(data_y): # len(data_x) can be bigger than len(data_y), which means you can have some x for prediction, you don't know there corresponding y value.\n",
    "        raise ValueError('Input data is invalid, Exit.')\n",
    "    if inx_p >= len(data_x) or (inx_p == -1 and inx_h + 1 >= len(data_x)): # Make sure data_x[inx_h + 1] exits\n",
    "        raise ValueError('inx_p provided is out of the bound of data_x, Exit.')\n",
    "    if inx_h - l_inx + 1 < 0: # Make sure data_x[inx_h - l_inx + 1] exits\n",
    "        raise ValueError('l_inx provided is out of the bound of data_x, Exit.')\t\n",
    "    if inx_p == -1: # If inx_p is set to -1, the point with index (inx_h + 1) will be predicted\n",
    "        inx_p = inx_h + 1\n",
    "    if inx_p + n_pred - 1 >= len(data_x): # Make sure data_x[inx_p + n_pred - 1] exits\n",
    "        raise ValueError('n_pred provided is out of the bound of data_x, Exit.')\n",
    "\n",
    "\n",
    "    pool = Pool(thread_num)\n",
    "    n_lines = len(data_x) // N # TODO: if cannot be completely divided\n",
    "    history_inx = list(range(inx_h - l_inx + 1, inx_h + 1))\n",
    "    random.shuffle(history_inx)\n",
    "    shuffle_inx = np.resize(np.array(history_inx), (N, n_lines)) # Generate a shuffled ndarray of size: N * n_lines\n",
    "    print(\"Shuffled inx is: \")\n",
    "    print(shuffle_inx)\n",
    "    print(\"====================================================\")\n",
    "\n",
    "    if s_size > 0 and n_pred > 0: # Do slide prediction\n",
    "        n_iter = n_pred\n",
    "    else: # Predict once\n",
    "        n_iter = 1\n",
    "    all_iter = n_iter\n",
    "\n",
    "    reg_results = []\n",
    "    pred_results = {}\n",
    "\n",
    "    while n_iter > 0:\n",
    "        slide_time = all_iter - n_iter\n",
    "        print(\"... ... This is iteration %s ... ...\" % (slide_time + 1))\n",
    "        print(\"====================================================\")\n",
    "        if slide_time == 0:\t# The 1st time, run all n_lines regressions\n",
    "            # 1. Parallely perform Linear regression\n",
    "            train_sets = [(data_x[list(shuffle_inx[i])], data_y[list(shuffle_inx[i])], i) for i in range(n_lines)]\n",
    "            if len(data_y) <= inx_p:\n",
    "                test_set = (data_x[inx_p], None)\n",
    "            else:\n",
    "                test_set = (data_x[inx_p], data_y[inx_p])\n",
    "            func = partial(fit_linear_model, test_set)\n",
    "            reg_results = pool.map(func, train_sets)\n",
    "            print(\"Regression result - inx, (regr.coef_[0,0], regr.intercept_[0]), regr._residues[0], pred_y[0,0], pred_resid:\")\n",
    "            print(reg_results) # It looks like: [(0, (0.99, 2.00), 2.07e-12, 51.00, None), (...), (...)]\n",
    "            print(\"====================================================\")\n",
    "\n",
    "            # 2. Calculate weights using forward_losses\n",
    "            forward_losses = [reg_result[2] for reg_result in reg_results]\n",
    "            weights = calculate_weight(forward_losses, method)\n",
    "            print(\"Weights are %s\" % str(weights))\n",
    "\n",
    "            # 3. Final prediction using weighted avg\n",
    "            preds = [reg_result[3] for reg_result in reg_results]\n",
    "            pred = np.average(preds, weights = weights)\n",
    "            pred_results[slide_time] = pred\n",
    "            print(\"Prediction is %f\" % pred)\n",
    "            print(\"====================================================\")\n",
    "\n",
    "        else: # Window slides, update previous reg_results, forward_losses, weights and pred\n",
    "            # 1. Check if there are history data available for new iteration\n",
    "            if inx_h + 1 >= len(data_x):\n",
    "                raise ValueError('After window slides, and inx_h is out of the bound of data_x, Exit.')\n",
    "            if inx_h + 1 >= len(data_y):\n",
    "                raise ValueError(\"WARN: After window slides, no real y value available for index inx_h.\") # TODO: may use predicted y value here\n",
    "\n",
    "            # 2. Slide the window and refactor shuffle_inx\n",
    "            inx_in = inx_h\n",
    "            inx_out = inx_h - l_inx\n",
    "            print(\"After window slides, point at %s is involved, point at %s is eliminated\" % (inx_in, inx_out))\n",
    "            print(\"====================================================\")\n",
    "            inx_replace = np.where(shuffle_inx == inx_out)\n",
    "            shuffle_inx[inx_replace] = inx_in\n",
    "            print(\"After window slides, Shuffled inx changes to: \")\n",
    "            print(shuffle_inx)\n",
    "            print(\"====================================================\")\n",
    "\n",
    "            # 3. Perform Linear regression only for new lines and update previous reg_results\n",
    "            changed_lines = inx_replace[0].flatten()\n",
    "            previous_results = reg_results\n",
    "            train_sets = [(data_x[list(shuffle_inx[i])], data_y[list(shuffle_inx[i])], i) for i in changed_lines]\n",
    "            if len(data_y) <= inx_p:\n",
    "                test_set = (data_x[inx_p], None)\n",
    "            else:\n",
    "                test_set = (data_x[inx_p], data_y[inx_p])\n",
    "            func = partial(fit_linear_model, test_set)\n",
    "            reg_results = pool.map(func, train_sets)\n",
    "            print(\"Regression result - inx, (regr.coef_[0,0], regr.intercept_[0]), regr._residues[0], pred_y[0,0], pred_resid:\")\n",
    "            print(reg_results) # It looks like: [(0, (0.99, 2.00), 2.07e-12, 51.00, None), (...), (...)]\n",
    "            print(\"====================================================\")\n",
    "            changed_inx = [e[0] for e in previous_results].index(changed_lines)\n",
    "            previous_results[changed_inx] = reg_results[0] # TODO: hard coding to get the 1st item in reg_results. If predict multiple items will get error\n",
    "            print(\"Refactor Previous Regression result to: \")\n",
    "            print(previous_results)\n",
    "            print(\"====================================================\")\n",
    "\n",
    "            # 4. Calculate weights using forward_losses\n",
    "            forward_losses = [reg_result[2] for reg_result in previous_results]\n",
    "            weights = calculate_weight(forward_losses, method)\n",
    "            print(\"Weights are %s\" % str(weights))\n",
    "\n",
    "            # 5. Final prediction using weighted avg\n",
    "            preds = [reg_result[3] for reg_result in previous_results]\n",
    "            pred = np.average(preds, weights = weights)\n",
    "            pred_results[slide_time] = pred\n",
    "            print(\"Prediction is %f\" % pred)\n",
    "            print(\"====================================================\")\n",
    "            reg_results = previous_results # Store this previous_results for next iteration\n",
    "\n",
    "        # Update iterators\n",
    "        inx_h += 1\n",
    "        inx_p += 1\n",
    "        n_iter -= 1\n",
    "\n",
    "    # Close the pool\n",
    "    pool.close()\n",
    "    return pred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_linear_model(test_set, train_set):\n",
    "    regr = linear_model.LinearRegression()\n",
    "    train_x = np.resize(train_set[0], (-1, 1))\n",
    "    train_y = np.resize(train_set[1], (-1, 1))\n",
    "    inx = train_set[2] # The uid of this line, corresponding to its row id in shuffle_inx\n",
    "    test_x = np.array(test_set[0]).reshape(-1, 1) \n",
    "    test_y = np.array(test_set[1]).reshape(-1, 1) \n",
    "    regr.fit(train_x, train_y) # training\n",
    "    pred_y = regr.predict(test_x) # predict - test_x should be 2D\n",
    "    if test_y != None: # If know the real y value\n",
    "        pred_resid = (pred_y - test_y) ** 2\n",
    "    else: # If do not know the real y value\n",
    "        pred_resid = None\n",
    "    # A thread (a line) returns something like this: (0, (0.99, 2.00), 2.07e-12, 51.00, None)\n",
    "    return inx, (regr.coef_[0,0], regr.intercept_[0]), regr._residues[0], pred_y[0,0], pred_resid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weight(forward_losses, method='inverse'):\n",
    "    # calulate inverse\n",
    "    forward_losses = np.array(forward_losses)\n",
    "    if method == 'inverse':\n",
    "        inverse_losses = (1.0 + 1e-50) / (forward_losses + 1e-50) # avoid divided by 0\n",
    "        weights = scale_one(inverse_losses) # scale to one\n",
    "    elif method == 'softmax':\n",
    "        weights = np.exp(forward_losses) / np.sum(np.exp(forward_losses), axis=0)\n",
    "    else:\n",
    "        raise ValueError('Weight calculation method is invalid, Exit.')\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_one(x):\n",
    "    return x / np.sum(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled inx is: \n",
      "[[44 13 23 32 34 15 39]\n",
      " [38 45 36 43  0 40 10]\n",
      " [29  5 35 22  7 30 48]\n",
      " [17 14  3 28 24  4 42]\n",
      " [37  8 31 27  6 19 33]\n",
      " [18 11 25 16 21 26 41]\n",
      " [ 9 46  1  2 20 12 47]]\n",
      "====================================================\n",
      "... ... This is iteration 1 ... ...\n",
      "====================================================\n",
      "Regression result - inx, (regr.coef_[0,0], regr.intercept_[0]), regr._residues[0], pred_y[0,0], pred_resid:\n",
      "[(0, (0.9999999999999999, 2.0000000000000036), 7.099748146989106e-30, 51.0, array([[0.]])), (1, (1.0, 2.0), 5.383975678133406e-29, 51.0, array([[0.]])), (2, (1.0000000000000004, 1.9999999999999893), 3.1603740015416785e-29, 51.000000000000014, array([[2.01948392e-28]])), (3, (0.9999999999999999, 2.0000000000000018), 2.2137409152764644e-29, 50.99999999999999, array([[5.04870979e-29]])), (4, (1.0000000000000004, 1.9999999999999893), 7.888609052210118e-31, 51.000000000000014, array([[2.01948392e-28]])), (5, (0.9999999999999998, 2.0000000000000036), 4.979684464207637e-30, 50.999999999999986, array([[2.01948392e-28]])), (6, (1.0000000000000002, 1.9999999999999964), 1.9129876951609536e-29, 51.000000000000014, array([[2.01948392e-28]]))]\n",
      "====================================================\n",
      "Weights are [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "Prediction is 51.000000\n",
      "====================================================\n",
      "... ... This is iteration 2 ... ...\n",
      "====================================================\n",
      "After window slides, point at 49 is involved, point at 0 is eliminated\n",
      "====================================================\n",
      "After window slides, Shuffled inx changes to: \n",
      "[[44 13 23 32 34 15 39]\n",
      " [38 45 36 43 49 40 10]\n",
      " [29  5 35 22  7 30 48]\n",
      " [17 14  3 28 24  4 42]\n",
      " [37  8 31 27  6 19 33]\n",
      " [18 11 25 16 21 26 41]\n",
      " [ 9 46  1  2 20 12 47]]\n",
      "====================================================\n",
      "Regression result - inx, (regr.coef_[0,0], regr.intercept_[0]), regr._residues[0], pred_y[0,0], pred_resid:\n",
      "[(1, (1.0000000000000002, 1.999999999999993), 2.6131017485446016e-30, 52.00000000000001, array([[5.04870979e-29]]))]\n",
      "====================================================\n",
      "Refactor Previous Regression result to: \n",
      "[(0, (0.9999999999999999, 2.0000000000000036), 7.099748146989106e-30, 51.0, array([[0.]])), (1, (1.0000000000000002, 1.999999999999993), 2.6131017485446016e-30, 52.00000000000001, array([[5.04870979e-29]])), (2, (1.0000000000000004, 1.9999999999999893), 3.1603740015416785e-29, 51.000000000000014, array([[2.01948392e-28]])), (3, (0.9999999999999999, 2.0000000000000018), 2.2137409152764644e-29, 50.99999999999999, array([[5.04870979e-29]])), (4, (1.0000000000000004, 1.9999999999999893), 7.888609052210118e-31, 51.000000000000014, array([[2.01948392e-28]])), (5, (0.9999999999999998, 2.0000000000000036), 4.979684464207637e-30, 50.999999999999986, array([[2.01948392e-28]])), (6, (1.0000000000000002, 1.9999999999999964), 1.9129876951609536e-29, 51.000000000000014, array([[2.01948392e-28]]))]\n",
      "====================================================\n",
      "Weights are [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "Prediction is 51.142857\n",
      "====================================================\n",
      "... ... This is iteration 3 ... ...\n",
      "====================================================\n",
      "After window slides, point at 50 is involved, point at 1 is eliminated\n",
      "====================================================\n",
      "After window slides, Shuffled inx changes to: \n",
      "[[44 13 23 32 34 15 39]\n",
      " [38 45 36 43 49 40 10]\n",
      " [29  5 35 22  7 30 48]\n",
      " [17 14  3 28 24  4 42]\n",
      " [37  8 31 27  6 19 33]\n",
      " [18 11 25 16 21 26 41]\n",
      " [ 9 46 50  2 20 12 47]]\n",
      "====================================================\n",
      "Regression result - inx, (regr.coef_[0,0], regr.intercept_[0]), regr._residues[0], pred_y[0,0], pred_resid:\n",
      "[(6, (1.0, 2.0), 1.2818989709841442e-29, 53.0, array([[0.]]))]\n",
      "====================================================\n",
      "Refactor Previous Regression result to: \n",
      "[(0, (0.9999999999999999, 2.0000000000000036), 7.099748146989106e-30, 51.0, array([[0.]])), (1, (1.0000000000000002, 1.999999999999993), 2.6131017485446016e-30, 52.00000000000001, array([[5.04870979e-29]])), (2, (1.0000000000000004, 1.9999999999999893), 3.1603740015416785e-29, 51.000000000000014, array([[2.01948392e-28]])), (3, (0.9999999999999999, 2.0000000000000018), 2.2137409152764644e-29, 50.99999999999999, array([[5.04870979e-29]])), (4, (1.0000000000000004, 1.9999999999999893), 7.888609052210118e-31, 51.000000000000014, array([[2.01948392e-28]])), (5, (0.9999999999999998, 2.0000000000000036), 4.979684464207637e-30, 50.999999999999986, array([[2.01948392e-28]])), (6, (1.0, 2.0), 1.2818989709841442e-29, 53.0, array([[0.]]))]\n",
      "====================================================\n",
      "Weights are [0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714\n",
      " 0.14285714]\n",
      "Prediction is 51.428571\n",
      "====================================================\n",
      "{0: 51.000000000000014, 1: 51.14285714285716, 2: 51.428571428571445}\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "##          Main          ##\n",
    "############################\n",
    "if __name__ == '__main__':\n",
    "    data_x = np.arange(55)\n",
    "    data_y = np.arange(54) + 2.0\n",
    "    inx_h, l_inx, N, n_pred, s_size = 48, 49, 7, 3, 1\n",
    "    method = 'softmax'\n",
    "    pred_results = random_pursuit(data_x, data_y, inx_h, l_inx, N, -1, n_pred, s_size, -1, method)\n",
    "    print(pred_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
